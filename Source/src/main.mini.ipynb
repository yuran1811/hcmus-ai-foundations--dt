{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947422a3",
   "metadata": {},
   "source": [
    "# Project 03: Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67c75e8",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ced47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.path import DATA_CARS, DATA_WDBC, DATA_WINE, FIG_DIR\n",
    "from constants.base import RATIOS\n",
    "from utils import display_ratio, normalize_dataset_name, normalize_dataset_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f6971",
   "metadata": {},
   "source": [
    "## Dataset Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_df = pd.read_csv(DATA_WDBC, sep=\",\")\n",
    "# Map labels (M=0, B=1) to align with sklearn's encoding\n",
    "breast_df = breast_df[breast_df[\"Diagnosis\"].isin([\"M\", \"B\"])]\n",
    "\n",
    "# Prepare features and labels\n",
    "y_breast = breast_df[\"Diagnosis\"].map({\"M\": 0, \"B\": 1})\n",
    "X_breast = breast_df.drop(\"Diagnosis\", axis=1)\n",
    "\n",
    "# Verify dataset integrity\n",
    "# print(\"Unique Diagnosis values:\", breast_df[\"Diagnosis\"].unique())\n",
    "# print(\"Unique y_breast:\", y_breast.unique())\n",
    "# print(\"Number of features:\", X_breast.shape[1])\n",
    "# print(\"Feature Names:\\n\", len(X_breast.columns.tolist()), (X_breast.columns.tolist()))\n",
    "# print(\"\\nClass Distribution:\\n\", y_breast.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(DATA_WINE, sep=\",\")\n",
    "# Group into 3 quality categories\n",
    "wine_df[\"quality_group\"] = pd.cut(\n",
    "    wine_df[\"quality\"], bins=[-1, 4, 6, 10], labels=[\"Low\", \"Standard\", \"High\"]\n",
    ")\n",
    "\n",
    "# Prepare features and labels\n",
    "y_wine = wine_df[\"quality_group\"]\n",
    "X_wine = wine_df.drop([\"quality\", \"quality_group\"], axis=1)\n",
    "\n",
    "# Verify class distribution\n",
    "# print(\"Quality Group Distribution:\")\n",
    "# print(y_wine.value_counts())\n",
    "# print(\"Unique y_wine:\", y_wine.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace847af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Additional Dataset: Car Evaluation Dataset\n",
    "\n",
    "This dataset meets all project requirements:\n",
    "\t+ Source: UCI Machine Learning Repository\n",
    "\t+ Classes: 4 (unacc, acc, good, vgood)\n",
    "\t+ Samples: 1728\n",
    "\n",
    "Features: 6 categorical attributes (buying price, maintenance cost, doors, etc.).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "car_df = pd.read_csv(DATA_CARS, sep=\",\")\n",
    "\n",
    "# One-Hot Encode Categorical Features\n",
    "y_car = car_df[\"class\"]\n",
    "X_car = pd.get_dummies(car_df.drop(\"class\", axis=1))\n",
    "\n",
    "# Verify Dataset Compliance\n",
    "# print(f\"Total Samples: {len(car_df)}\")  # Output: 1728\n",
    "# print(\"Class Distribution:\\n\", y_car.value_counts())\n",
    "# print(\"class names:\\n\", y_car.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe38e8",
   "metadata": {},
   "source": [
    "## 2.1 - Data Splitting and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_visualize(X, y, dataset_name: str):\n",
    "    splits = {}\n",
    "\n",
    "    for ratio in RATIOS:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, train_size=ratio, stratify=y, shuffle=True, random_state=42\n",
    "        )\n",
    "\n",
    "        splits[ratio] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Class distribution visualization\n",
    "        _, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "        (\n",
    "            pd.Series(y)\n",
    "            .value_counts(normalize=True)\n",
    "            .plot(kind=\"bar\", ax=axes[0], title=f\"Original ({len(y)} samples)\")\n",
    "        )\n",
    "        (\n",
    "            pd.Series(y_train)\n",
    "            .value_counts(normalize=True)\n",
    "            .plot(kind=\"bar\", ax=axes[1], title=f\"Train ({len(y_train)} samples)\")\n",
    "        )\n",
    "        (\n",
    "            pd.Series(y_test)\n",
    "            .value_counts(normalize=True)\n",
    "            .plot(kind=\"bar\", ax=axes[2], title=f\"Test ({len(y_test)} samples)\")\n",
    "        )\n",
    "\n",
    "        plt.suptitle(f\"{dataset_name} - {display_ratio(ratio)} Split\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"{FIG_DIR}/class_dist/class_dist__{normalize_dataset_name(dataset_name)}__{normalize_dataset_ratio(ratio)}.png\"\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723ab64",
   "metadata": {},
   "source": [
    "## 2.2, 2.3 - Decision Tree Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_decision_tree(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    dataset_name: str,\n",
    "    split_ratio,\n",
    "):\n",
    "    # Dynamically set feature and class names\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    class_names = [str(cls) for cls in np.unique(y_train)]\n",
    "\n",
    "    # Train model\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Classification Report (with validation)\n",
    "    print(f\"\\nClassification Report ({dataset_name}, {display_ratio(split_ratio)}):\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            target_names=class_names,\n",
    "            labels=np.unique(y_test),  # Ensure alignment with actual classes\n",
    "        )\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "        confusion_matrix(y_test, y_pred),\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.title(f\"Confusion Matrix - {dataset_name} ({display_ratio(split_ratio)})\")\n",
    "    plt.savefig(\n",
    "        f\"{FIG_DIR}/confusion_mat/confusion_mat__{normalize_dataset_name(dataset_name)}__{normalize_dataset_ratio(split_ratio)}.png\"\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Export Decision Tree Visualization\n",
    "    dot_data = export_graphviz(\n",
    "        clf,\n",
    "        out_file=None,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "    )\n",
    "    img = mpimg.imread(\n",
    "        graphviz.Source(dot_data).render(\n",
    "            f\"{FIG_DIR}/dt/dt__{normalize_dataset_name(dataset_name)}__{normalize_dataset_ratio(split_ratio)}\",\n",
    "            format=\"png\",\n",
    "            cleanup=True,\n",
    "        )\n",
    "    )\n",
    "    height, width = img.shape[:2]\n",
    "    dpi = plt.rcParams[\"figure.dpi\"]\n",
    "    _, ax = plt.subplots(figsize=(width / dpi, height / dpi))\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    plt.title(f\"Decision Tree - {dataset_name} ({display_ratio(split_ratio)})\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ece6b",
   "metadata": {},
   "source": [
    "## 2.4 - Depth vs. Accuracy Analysis (80/20 Split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be58880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_accuracy_analysis(X, y, feature_names, class_names, dataset_name: str):\n",
    "    # 80/20 split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=0.8, stratify=y, shuffle=True, random_state=42\n",
    "    )\n",
    "\n",
    "    # Test depths\n",
    "    max_depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "    accuracies = []\n",
    "\n",
    "    for depth in max_depths:\n",
    "        # Train with depth constraint\n",
    "        clf = DecisionTreeClassifier(\n",
    "            criterion=\"entropy\", max_depth=depth, random_state=42\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        dot_data = export_graphviz(\n",
    "            clf,\n",
    "            out_file=None,\n",
    "            feature_names=feature_names,\n",
    "            class_names=class_names,\n",
    "            filled=True,\n",
    "            rounded=True,\n",
    "        )\n",
    "        img = mpimg.imread(\n",
    "            graphviz.Source(dot_data).render(\n",
    "                f\"{FIG_DIR}/dt/dt__{normalize_dataset_name(dataset_name)}__{normalize_dataset_ratio(0.8)}__{depth}\",\n",
    "                format=\"png\",\n",
    "                cleanup=True,\n",
    "            )\n",
    "        )\n",
    "        height, width = img.shape[:2]\n",
    "        dpi = plt.rcParams[\"figure.dpi\"]\n",
    "        _, ax = plt.subplots(figsize=(width / dpi, height / dpi))\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        plt.title(f\"Decision Tree - {dataset_name} (80/20) (depth={depth})\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # Accuracy vs Depth Plot\n",
    "    plt.title(f\"{dataset_name} - Accuracy vs. Tree Depth (80/20 Split)\")\n",
    "    plt.plot([str(d) if d else \"Unlimited\" for d in max_depths], accuracies, marker=\"o\")\n",
    "    plt.xlabel(\"Max Tree Depth\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.grid(linestyle=\"--\")\n",
    "    plt.savefig(\n",
    "        f\"{FIG_DIR}/accuracy_vs_depth_{normalize_dataset_name(dataset_name)}.png\"\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Return results as DataFrame\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Max Depth\": [x if x is not None else \"None\" for x in max_depths],\n",
    "            \"Accuracy\": accuracies,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fd801",
   "metadata": {},
   "source": [
    "## Training and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a612166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{FIG_DIR}/class_dist\", exist_ok=True)\n",
    "os.makedirs(f\"{FIG_DIR}/confusion_mat\", exist_ok=True)\n",
    "os.makedirs(f\"{FIG_DIR}/dt\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65178a58",
   "metadata": {},
   "source": [
    "### Breast Cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ecb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Breast Cancer\"\n",
    "\n",
    "splitted_tests = split_and_visualize(X_breast, y_breast, dataset_name)\n",
    "for ratio in RATIOS:\n",
    "    X_train, X_test, y_train, y_test = splitted_tests[ratio]\n",
    "    train_evaluate_decision_tree(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        ratio,\n",
    "    )\n",
    "\n",
    "feature_names = X_breast.columns.tolist()\n",
    "class_names = [\"Malignant\", \"Benign\"]  # Must match y_breast.unique()\n",
    "depth_results = depth_accuracy_analysis(\n",
    "    X_breast, y_breast, feature_names, class_names, dataset_name\n",
    ")\n",
    "print(f\"\\nDepth Analysis Results for {dataset_name}:\\n\", depth_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c854e",
   "metadata": {},
   "source": [
    "### Wine Quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6cecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Wine Quality\"\n",
    "\n",
    "splitted_tests = split_and_visualize(X_wine, y_wine, dataset_name)\n",
    "for ratio in RATIOS:\n",
    "    X_train, X_test, y_train, y_test = splitted_tests[ratio]\n",
    "    train_evaluate_decision_tree(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        ratio,\n",
    "    )\n",
    "\n",
    "feature_names = X_wine.columns.tolist()\n",
    "class_names = [\"Standard\", \"High\", \"Low\"]  # Must match y_wine.unique()\n",
    "depth_results = depth_accuracy_analysis(\n",
    "    X_wine, y_wine, feature_names, class_names, dataset_name\n",
    ")\n",
    "print(f\"\\nDepth Analysis Results for {dataset_name}:\\n\", depth_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf15f6b",
   "metadata": {},
   "source": [
    "### Car Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Car Evaluation\"\n",
    "\n",
    "splitted_tests = split_and_visualize(X_car, y_car, dataset_name)\n",
    "for ratio in RATIOS:\n",
    "    X_train, X_test, y_train, y_test = splitted_tests[ratio]\n",
    "    train_evaluate_decision_tree(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        ratio,\n",
    "    )\n",
    "\n",
    "feature_names = X_car.columns.tolist()\n",
    "class_names = [\"unacc\", \"acc\", \"vgood\", \"good\"]  # Must match y_car.unique()\n",
    "depth_results = depth_accuracy_analysis(\n",
    "    X_car, y_car, feature_names, class_names, dataset_name\n",
    ")\n",
    "print(f\"\\nDepth Analysis Results for {dataset_name}:\\n\", depth_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
