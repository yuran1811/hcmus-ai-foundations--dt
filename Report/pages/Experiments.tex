\section{Dataset Analysis and Experiments}
\subsection{Dataset Preparation and Preprocessing}
\begin{minted}{py}
def split_and_visualize(X, y, dataset_name: str):
    splits = {}

    for ratio in [0.4, 0.6, 0.8, 0.9]:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, train_size=ratio, stratify=y, shuffle=True, random_state=42
        )

        splits[ratio] = (X_train, X_test, y_train, y_test)

    return splits
\end{minted}
\begin{flushleft}
	To shuffle the dataset and ensure it is split in a stratified fashion, we use the \texttt{train\_test\_split} function from \texttt{sklearn.model\_selection}. The function takes the dataset and the target variable as inputs, along with the desired train-test split ratio.
	\begin{itemize}
		\item The \texttt{shuffle} parameter randomizes the order of the samples before splitting.
		\item The \texttt{stratify} parameter ensures the dataset is split in a stratified fashion.
	\end{itemize}
\end{flushleft}

\subsection{Interpreting Classification Report and Confusion Matrix}
\begin{minted}{py}
def train_evaluate_decision_tree(
    X_train,
    y_train,
    X_test,
    y_test,
    dataset_name: str,
    split_ratio,
):
    # Dynamically set feature and class names
    feature_names = X_train.columns.tolist()
    class_names = [str(cls) for cls in np.unique(y_train)]

    # Train model
    clf = DecisionTreeClassifier(criterion="entropy", random_state=42)
    clf.fit(X_train, y_train)

    # Predictions
    y_pred = clf.predict(X_test)

    # Classification Report (with validation)
    print(f"\nClassification Report ({dataset_name}, {display_ratio(split_ratio)}):")
    print(
        classification_report(
            y_test,
            y_pred,
            target_names=class_names,
            labels=np.unique(y_test),  # Ensure alignment with actual classes
        )
    )

    # Confusion Matrix
    sns.heatmap(
        confusion_matrix(y_test, y_pred),
        annot=True,
        fmt="d",
        xticklabels=class_names,
        yticklabels=class_names,
    )
\end{minted}
\begin{flushleft}
	To generate the classification report and confusion matrix:
	\begin{itemize}
		\item The \texttt{classification\_report} function provides a detailed report of the model's performance, including precision, recall, and F1-score for each class.
		\item The \texttt{confusion\_matrix} function generates a matrix that shows the number of correct and incorrect predictions for each class.
	\end{itemize}
\end{flushleft}

\subsection{Classification Report and Confusion Matrix Interpretion}
\begin{flushleft}
	\begin{itemize}
		\item The classification report summarizes, for each class \(c\):
		      \begin{itemize}
			      \item \textbf{Precision} (\(\mathrm{Prec}_c\)): measures the fraction of samples predicted as \(c\) that truly belong to \(c\).
			      \item \textbf{Recall} (\(\mathrm{Rec}_c\)): measures the fraction of true-\(c\) samples correctly identified.
			      \item \textbf{F1‑score} (\(\mathrm{F1}_c\)): the harmonic mean of precision and recall
			      \item \textbf{Support}: the number of true samples of class \(c\).
		      \end{itemize}
		\item For example, with a binary problem (classes “positive”/“negative”), the confusion matrix is:
		      \begin{flushleft}
			      \[
				      \mathbf{CM} =
				      \begin{pmatrix}
					      \mathrm{TN} & \mathrm{FP} \\
					      \mathrm{FN} & \mathrm{TP}
				      \end{pmatrix},
			      \]
			      where
			      \begin{description}
				      \item[\(\mathrm{TN}\) (True Negative):] correctly predicted negatives.
				      \item[\(\mathrm{FP}\) (False Positive, Type I error):] negatives incorrectly predicted as positives.
				      \item[\(\mathrm{FN}\) (False Negative, Type II error):] positives incorrectly predicted as negatives.
				      \item[\(\mathrm{TP}\) (True Positive):] correctly predicted positives.
			      \end{description}
			      \noindent From these entries we derive:
			      \begin{align*}
				      \text{Accuracy}                  & = \frac{\mathrm{TP} + \mathrm{TN}}{\mathrm{TP} + \mathrm{TN} + \mathrm{FP} + \mathrm{FN}}, \\
				      \text{False Positive Rate (FPR)} & = \frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}},                                           \\
				      \text{False Negative Rate (FNR)} & = \frac{\mathrm{FN}}{\mathrm{FN} + \mathrm{TP}}
			      \end{align*}
			      \begin{align*}
				      \text{Specificity (True Negative Rate)} & = \frac{\mathrm{TN}}{\mathrm{TN} + \mathrm{FP}}, \\
				      \text{Precision}                        & = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}, \\
				      \text{Recall (Sensitivity)}             & = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}
			      \end{align*}
			      \noindent A well‐performing classifier exhibits high \(\mathrm{TP}\) and \(\mathrm{TN}\), and low \(\mathrm{FP}\) and \(\mathrm{FN}\).
			      \begin{itemize}
				      \item \emph{High FP} indicates many false alarms.
				      \item \emph{High FN} indicates many misses—critical in domains such as medical diagnosis.
			      \end{itemize}
		      \end{flushleft}
	\end{itemize}
\end{flushleft}

%================ Breast Cancer =================%
\clearpage
\subsection{Breast Cancer Wisconsin Dataset}
\subsubsection*{Dataset Description}
\begin{itemize}
	\item \textbf{Description:} The UCI Breast Cancer Wisconsin (Diagnostic) dataset is used for classifying tumors as malignant or benign based on features derived from its imaging data.
	\item \textbf{Dataset Info:} 569 samples, binary labels (malignant vs.\ benign), 30 numeric features.
	\item \textbf{Preprocessing:} shuffle \& stratified split at 40/60, 60/40, 80/20, 90/10.
\end{itemize}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__breast_cancer__40_vs_60.png}
		\caption{Breast Cancer: class distribution (40/60 split).}\label{fig:bc-cd-40-60}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__breast_cancer__60_vs_40.png}
		\caption{Breast Cancer: class distribution (60/40 split).}\label{fig:bc-cd-60-40}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__breast_cancer__80_vs_20.png}
		\caption{Breast Cancer: class distribution (80/20 split).}\label{fig:bc-cd-80-20}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__breast_cancer__90_vs_10.png}
		\caption{Breast Cancer: class distribution (90/10 split).}\label{fig:bc-cd-90-10}
	\end{subfigure}

	\caption{Class distributions}\label{fig:bc-cd-all}
\end{figure}

% \clearpage
% \subsubsection*{Building Decision Tree Classifiers for each train/test proportions}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__40_vs_60.png}
% 	\caption{Breast Cancer: decision tree for 40/60 split.}\label{fig:bc-dt-40-60}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__60_vs_40.png}
% 	\caption{Breast Cancer: decision tree for 60/40 split.}\label{fig:bc-dt-60-40}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20.png}
% 	\caption{Breast Cancer: decision tree for 80/20 split.}\label{fig:bc-dt-80-20}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__90_vs_10.png}
% 	\caption{Breast Cancer: decision tree for 90/10 split.}\label{fig:bc-dt-90-10}
% \end{figure}

\clearpage
\subsubsection*{Evaluating the decision tree classifiers}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__breast_cancer__40_vs_60.png}
		\caption{Breast Cancer: confusion matrix (40/60 split).}\label{fig:bc-cm-40-60}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__breast_cancer__40_vs_60.png}
		\caption{Breast Cancer: Classification Report (40/60 split).}\label{fig:bc-cr-40-60}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (40/60 split)}\label{fig:bc-eval-40-60}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__breast_cancer__60_vs_40.png}
		\caption{Breast Cancer: confusion matrix (60/40 split).}\label{fig:bc-cm-60-40}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__breast_cancer__60_vs_40.png}
		\caption{Breast Cancer: Classification Report (60/40 split).}\label{fig:bc-cr-60-40}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (60/40 split)}\label{fig:bc-eval-60-40}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__breast_cancer__80_vs_20.png}
		\caption{Breast Cancer: confusion matrix (80/20 split).}\label{fig:bc-cm-80-20}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__breast_cancer__80_vs_20.png}
		\caption{Breast Cancer: Classification Report (80/20 split).}\label{fig:bc-cr-80-20}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (80/20 split)}\label{fig:bc-eval-80-20}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__breast_cancer__90_vs_10.png}
		\caption{Breast Cancer: confusion matrix (90/10 split).}\label{fig:bc-cm-90-10}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__breast_cancer__90_vs_10.png}
		\caption{Breast Cancer: Classification Report (90/10 split).}\label{fig:bc-cr-90-10}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (90/10 split)}\label{fig:bc-eval-90-10}
\end{figure}

\subsubsection*{Insights – Performance Evaluation}
\begin{itemize}
	\item \textbf{High malignant detection (Recall):} On the 80/20 test set, the model correctly identified over 90\% of malignant tumors (few false negatives), which is vital to minimize missed diagnoses.
	\item \textbf{Strong benign precision:} Precision for the benign class exceeded 85\%, meaning that fewer than 15\% of predicted benign cases were actually malignant—reducing unnecessary alarm.
	\item \textbf{Balanced error trade‑off:} False positives (benign mislabeled malignant) remained below 10\% while false negatives (malignant missed) stayed under 8\%, demonstrating a well‑calibrated decision boundary.
	\item \textbf{Stable across splits:} Moving from small (40/60) to large (90/10) training sets shifted accuracy only by ~1–2\%, indicating robustness to training‑set size.
	\item \textbf{Key features aligned with domain knowledge:} The top‐level split on \texttt{concave\_points3} (shape irregularity) and the next split on \texttt{area3} (size) match clinical understanding that tumor shape and size are strong malignancy indicators.
\end{itemize}

\clearpage
\subsubsection*{Decision Tree Classifier with Different Depths}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20__2.png}
	\caption{Breast Cancer: decision tree with \texttt{max\_depth}=2 (80/20 split).}\label{fig:bc-dt-depth-2}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20__3.png}
	\caption{Breast Cancer: decision tree with \texttt{max\_depth}=3 (80/20 split).}\label{fig:bc-dt-depth-3}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20__4.png}
	\caption{Breast Cancer: decision tree with \texttt{max\_depth}=4 (80/20 split).}\label{fig:bc-dt-depth-4}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20__5.png}
	\caption{Breast Cancer: decision tree with \texttt{max\_depth}=5 (80/20 split).}\label{fig:bc-dt-depth-5}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20__6.png}
	\caption{Breast Cancer: decision tree with \texttt{max\_depth}=6 (80/20 split).}\label{fig:bc-dt-depth-6}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20__7.png}
	\caption{Breast Cancer: decision tree with \texttt{max\_depth}=7 (80/20 split).}\label{fig:bc-dt-depth-7}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__breast_cancer__80_vs_20__None.png}
	\caption{Breast Cancer: decision tree with \texttt{max\_depth}=None (80/20 split).}\label{fig:bc-dt-depth-none}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/accuracy_vs_depth_breast_cancer.png}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/accuracy_vs_depth_breast_cancer__analysis.png}
	\end{subfigure}
\end{figure}

\subsubsection*{Insights – Depth and Accuracy}
\begin{itemize}
	\item \textbf{Optimal generalization at depth 3:} Test accuracy peaked at ~94.7\% with max\_depth=3, compared to ~89.5\% at depth=2 (underfitting) and ~91.2\% with no depth limit (overfitting).
	\item \textbf{Overfitting beyond depth 3:} As max\_depth increased from 4 to 7, test accuracy gradually declined (~94.0\%→93.0\%→91.2\%), while training accuracy rose above 98\%, a classic overfitting signature.
	\item \textbf{Interpretability vs. performance:} A three‑level tree remains easily interpretable (just 7–9 nodes), yet captures most of the available information; deeper trees introduce many splits on noise.
	\item \textbf{Practical guideline:} For similar medical imaging tasks, limiting tree depth to 3–4 balances sensitivity with specificity and preserves model explainability.
\end{itemize}

%================ Wine Quality =================%
\clearpage
\subsection{Wine Quality Dataset}
\subsubsection*{Dataset Description}
\begin{itemize}
	\item \textbf{Description:} The UCI Wine Quality dataset is used for classifying wine samples into quality levels based on physicochemical properties such as acidity, alcohol content, etc.
	\item \textbf{Dataset Info:} 4898 samples, with labels from 0 (low quality) to 10 (high quality).
	\item \textbf{Preprocessing:} shuffle \& stratified split at 40/60, 60/40, 80/20, 90/10.
\end{itemize}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__wine_quality__40_vs_60.png}
		\caption{Wine Quality: class distribution (40/60 split).}\label{fig:wq-cd-40-60}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__wine_quality__60_vs_40.png}
		\caption{Wine Quality: class distribution (60/40 split).}\label{fig:wq-cd-60-40}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__wine_quality__80_vs_20.png}
		\caption{Wine Quality: class distribution (80/20 split).}\label{fig:wq-cd-80-20}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__wine_quality__90_vs_10.png}
		\caption{Wine Quality: class distribution (90/10 split).}\label{fig:wq-cd-90-10}
	\end{subfigure}

	\caption{Class distributions}\label{fig:wq-cd-all}
\end{figure}

% \clearpage
% \subsubsection*{Building Decision Tree Classifiers for each train/test proportions}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.8\textwidth]{imgs/dt-mini/dt__wine_quality__40_vs_60.png}
% 	\caption{Wine Quality: decision tree for 40/60 split.}\label{fig:wq-dt-40-60}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.8\textwidth]{imgs/dt-mini/dt__wine_quality__60_vs_40.png}
% 	\caption{Wine Quality: decision tree for 60/40 split.}\label{fig:wq-dt-60-40}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.8\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20.png}
% 	\caption{Wine Quality: decision tree for 80/20 split.}\label{fig:wq-dt-80-20}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.8\textwidth]{imgs/dt-mini/dt__wine_quality__90_vs_10.png}
% 	\caption{Wine Quality: decision tree for 90/10 split.}\label{fig:wq-dt-90-10}
% \end{figure}

\clearpage
\subsubsection*{Evaluating the decision tree classifiers}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__wine_quality__40_vs_60.png}
		\caption{Wine Quality: confusion matrix (40/60 split).}\label{fig:wq-cm-40-60}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__wine_quality__40_vs_60.png}
		\caption{Wine Quality: Classification Report (40/60 split).}\label{fig:wq-cr-40-60}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (40/60 split)}\label{fig:wq-eval-40-60}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__wine_quality__60_vs_40.png}
		\caption{Wine Quality: confusion matrix (60/40 split).}\label{fig:wq-cm-60-40}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__wine_quality__60_vs_40.png}
		\caption{Wine Quality: Classification Report (60/40 split).}\label{fig:wq-cr-60-40}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (60/40 split)}\label{fig:wq-eval-60-40}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__wine_quality__80_vs_20.png}
		\caption{Wine Quality: confusion matrix (80/20 split).}\label{fig:wq-cm-80-20}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__wine_quality__80_vs_20.png}
		\caption{Wine Quality: Classification Report (80/20 split).}\label{fig:wq-cr-80-20}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (80/20 split)}\label{fig:wq-eval-80-20}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__wine_quality__90_vs_10.png}
		\caption{Wine Quality: confusion matrix (90/10 split).}\label{fig:wq-cm-90-10}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__wine_quality__90_vs_10.png}
		\caption{Wine Quality: Classification Report (90/10 split).}\label{fig:wq-cr-90-10}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (90/10 split)}\label{fig:wq-eval-90-10}
\end{figure}


\subsubsection*{Insights – Performance Evaluation}
\begin{itemize}
	\item \textbf{Moderate overall accuracy:} Best split (80/20) achieved ~82\% accuracy—lower than Breast Cancer due to three overlapping quality classes.
	\item \textbf{“Standard” class confusion:} Wines labeled 5–6 were misclassified 28\% of the time, often as Low (acidic profiles) or High (high alcohol content), reflecting feature overlap.
	\item \textbf{Extremes well identified:} “Low” and “High” quality classes each attained \(\geq 75\%\) precision and recall, indicating distinct physicochemical signatures at the ends of the quality spectrum.
	\item \textbf{Effect of training size:} Accuracy varied by only ~3\% across splits, suggesting the dataset’s large sample size (4,898) mitigates sensitivity to train/test proportions.
\end{itemize}

\clearpage
\subsubsection*{Decision Tree Classifier with Different Depths}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20__2.png}
	\caption{Wine Quality: decision tree with \texttt{max\_depth}=2 (80/20 split).}\label{fig:wq-dt-depth-2}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20__3.png}
	\caption{Wine Quality: decision tree with \texttt{max\_depth}=3 (80/20 split).}\label{fig:wq-dt-depth-3}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20__4.png}
	\caption{Wine Quality: decision tree with \texttt{max\_depth}=4 (80/20 split).}\label{fig:wq-dt-depth-4}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20__5.png}
	\caption{Wine Quality: decision tree with \texttt{max\_depth}=5 (80/20 split).}\label{fig:wq-dt-depth-5}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20__6.png}
	\caption{Wine Quality: decision tree with \texttt{max\_depth}=6 (80/20 split).}\label{fig:wq-dt-depth-6}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20__7.png}
	\caption{Wine Quality: decision tree with \texttt{max\_depth}=7 (80/20 split).}\label{fig:wq-dt-depth-7}
\end{figure}

% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.8\textwidth]{imgs/dt-mini/dt__wine_quality__80_vs_20__None.png}
% 	\caption{Wine Quality: decision tree with \texttt{max\_depth}=None (80/20 split).}\label{fig:wq-dt-depth-none}
% \end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/accuracy_vs_depth_wine_quality.png}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/accuracy_vs_depth_wine_quality__analysis.png}
	\end{subfigure}
\end{figure}

\subsubsection*{Insights – Depth and Accuracy}
\begin{itemize}
	\item \textbf{Peak at depth 4:} Test accuracy climbed from ~78\% (depth 2) to ~82\% (depth 4) before dipping to ~80\% at deeper settings—underfitting at low depths, mild overfitting at high depths.
	\item \textbf{Complexity captures interactions:} Depth 4 allows the model to split on combined acidity–alcohol thresholds, improving discrimination of the mid‑quality group without modeling noise.
	\item \textbf{Shallow vs.\ deep trade‑off:} Depths \(<3\) fail to separate standard vs.\ high quality, while depths \(>5\) start splitting on rare minor features, hurting generalization.
	\item \textbf{Recommendation:} Use 3–5 levels for balanced performance on multi‑class regression proxies like wine quality.
\end{itemize}

%================ Car Evaluation =================%
\clearpage
\subsection{Car Evaluation Dataset}
\subsubsection*{Dataset Description}
\begin{itemize}
	\item \textbf{Description:} Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making.
	\item \textbf{Dataset Info:} 1728 samples, 4 classes (unacc, acc, good, vgood), 6 categorical attributes (buying price, maintenance cost, doors, etc.).
	\item \textbf{Preprocessing:} shuffle \& stratified split at 40/60, 60/40, 80/20, 90/10.
\end{itemize}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__car_evaluation__40_vs_60.png}
		\caption{Car Evaluation: class distribution (40/60 split).}\label{fig:ce-cd-40-60}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__car_evaluation__60_vs_40.png}
		\caption{Car Evaluation: class distribution (60/40 split).}\label{fig:ce-cd-60-40}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__car_evaluation__80_vs_20.png}
		\caption{Car Evaluation: class distribution (80/20 split).}\label{fig:ce-cd-80-20}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/class_dist/class_dist__car_evaluation__90_vs_10.png}
		\caption{Car Evaluation: class distribution (90/10 split).}\label{fig:ce-cd-90-10}
	\end{subfigure}

	\caption{Class distributions}\label{fig:ce-cd-all}
\end{figure}

% \clearpage
% \subsubsection*{Building Decision Tree Classifiers for each train/test proportions}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__40_vs_60.png}
% 	\caption{Car Evaluation: decision tree for 40/60 split.}\label{fig:ce-dt-40-60}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__60_vs_40.png}
% 	\caption{Car Evaluation: decision tree for 60/40 split.}\label{fig:ce-dt-60-40}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20.png}
% 	\caption{Car Evaluation: decision tree for 80/20 split.}\label{fig:ce-dt-80-20}
% \end{figure}
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__90_vs_10.png}
% 	\caption{Car Evaluation: decision tree for 90/10 split.}\label{fig:ce-dt-90-10}
% \end{figure}

\clearpage
\subsubsection*{Evaluating the decision tree classifiers}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__car_evaluation__40_vs_60.png}
		\caption{Car Evaluation: confusion matrix (40/60 split).}\label{fig:ce-cm-40-60}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__car_evaluation__40_vs_60.png}
		\caption{Car Evaluation: Classification Report (40/60 split).}\label{fig:ce-cr-40-60}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (40/60 split)}\label{fig:ce-eval-40-60}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__car_evaluation__60_vs_40.png}
		\caption{Car Evaluation: confusion matrix (60/40 split).}\label{fig:ce-cm-60-40}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__car_evaluation__60_vs_40.png}
		\caption{Car Evaluation: Classification Report (60/40 split).}\label{fig:ce-cr-60-40}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (60/40 split)}\label{fig:ce-eval-60-40}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__car_evaluation__80_vs_20.png}
		\caption{Car Evaluation: confusion matrix (80/20 split).}\label{fig:ce-cm-80-20}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__car_evaluation__80_vs_20.png}
		\caption{Car Evaluation: Classification Report (80/20 split).}\label{fig:ce-cr-80-20}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (80/20 split)}\label{fig:ce-eval-80-20}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/confusion_mat__car_evaluation__90_vs_10.png}
		\caption{Car Evaluation: confusion matrix (90/10 split).}\label{fig:ce-cm-90-10}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/confusion_mat/class_rp__car_evaluation__90_vs_10.png}
		\caption{Car Evaluation: Classification Report (90/10 split).}\label{fig:ce-cr-90-10}
	\end{subfigure}

	\caption{Classification Report and Confusion Matrix (90/10 split)}\label{fig:ce-eval-90-10}
\end{figure}

\subsubsection*{Insights – Performance Evaluation}
\begin{itemize}
	\item \textbf{Excellent detection of “unacc”:} Recall for the majority “unacc” class exceeded 95\%, ensuring most poor cars are flagged correctly.
	\item \textbf{Challenging rare classes:} The minority “vgood” class saw only ~68\% precision and recall, indicating that few “very good” examples hinder the model’s ability to learn those distinctions.
	\item \textbf{Categorical splits effective:} Attributes like \texttt{safety} and \texttt{buying} provided clean splits—e.g., “high safety” immediately boosted probability of “vgood” or “good”.
	\item \textbf{Stable across train sizes:} Accuracy varied by at most ~2.5\% from 40/60 to 90/10 splits, showing resilience even with fewer training examples.
\end{itemize}

\clearpage
\subsubsection*{Decision Tree Classifier with Different Depths}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20__2.png}
	\caption{Car Evaluation: decision tree with \texttt{max\_depth}=2 (80/20 split).}\label{fig:ce-dt-depth-2}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20__3.png}
	\caption{Car Evaluation: decision tree with \texttt{max\_depth}=3 (80/20 split).}\label{fig:ce-dt-depth-3}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20__4.png}
	\caption{Car Evaluation: decision tree with \texttt{max\_depth}=4 (80/20 split).}\label{fig:ce-dt-depth-4}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20__5.png}
	\caption{Car Evaluation: decision tree with \texttt{max\_depth}=5 (80/20 split).}\label{fig:ce-dt-depth-5}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20__6.png}
	\caption{Car Evaluation: decision tree with \texttt{max\_depth}=6 (80/20 split).}\label{fig:ce-dt-depth-6}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20__7.png}
	\caption{Car Evaluation: decision tree with \texttt{max\_depth}=7 (80/20 split).}\label{fig:ce-dt-depth-7}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{imgs/dt-mini/dt__car_evaluation__80_vs_20__None.png}
	\caption{Car Evaluation: decision tree with \texttt{max\_depth}=None (80/20 split).}\label{fig:ce-dt-depth-none}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/accuracy_vs_depth_car_evaluation.png}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{imgs/accuracy_vs_depth_car_evaluation__analysis.png}
	\end{subfigure}
\end{figure}

\subsubsection*{Insights – Depth and Accuracy}
\begin{itemize}
	\item \textbf{Best performance at depth 5:} Accuracy rose from ~89\% (depth 2) to ~93\% (depth 5) before plateauing and slightly falling at greater depths.
	\item \textbf{Overfitting rare combinations:} Depth 7+ began memorizing very specific door–lug\_boot–safety combos that occur only once or twice, harming generalization.
	\item \textbf{Interpretability maintained:} A five‑level tree remains comprehensible (<50 nodes) yet flexible enough to model interactions among six categorical features.
	\item \textbf{Practical advice:} For multi‐class categorical problems, depths of 4–6 capture non‑linear splits while avoiding noise-induced overfitting.
\end{itemize}
